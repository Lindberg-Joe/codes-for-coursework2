import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.autograd import Variable
import datetime

Input_size=3072
Output_size=10
Num_of_eopchs=20
Batch_size=64
alpha=0.01

transform=transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])

train_set=torchvision.datasets.CIFAR10(root='/E/CIFAR10/',train=True,download=False,
                                       transform=transform)
test_set=torchvision.datasets.CIFAR10(root='/E/CIFAR10/',train=False,download=False,
                                      transform=transform)

train_loader=torch.utils.data.DataLoader(dataset=train_set,
                                        batch_size=Batch_size,
                                        shuffle=True)
test_loader=torch.utils.data.DataLoader(dataset=test_set,
                                        batch_size=Batch_size,
                                        shuffle=True)

model=nn.Linear(Input_size,Output_size)

criterion=nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=alpha)

total_step=len(train_loader)

for epoch in range(Num_of_eopchs):
    start_time=datetime.datetime.now()
    running_loss=0.0
    for i,(x,y) in enumerate(train_loader):
        optimizer.zero_grad()
        x=x.reshape(-1,32*32*3)
        output=model(x)
        #y=Variable(y)
        loss=criterion(output,y)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() 
        if (i+1) % 782 == 0:
            print ('Epoch [{}/{}], Loss: {:.4f}' 
                   .format(epoch+1, Num_of_eopchs, running_loss / 300))
            running_loss=0.0
            
with torch.no_grad():
    exact_num=0
    total=0
    for x,y in test_loader:
        x=x.reshape(-1,32*32*3)
        output=model(x)
        _,pred=torch.max(output.data,dim=1)
        total+=y.size(0)
        exact_num+=(pred==y).sum().item()
    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * exact_num / total))
